{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "Probability theory has an infamous inception for its association with gambling. Monte Carlo, the European casino capital, is another unfortunate presence. However, naming it Macau simulation or Hong Kong Jockey Club simulation does not make me feel any better. I decide to simply call it \"simulation\".\n",
    "\n",
    "Simulation has been widely used for (i) checking finite-sample performance of asymptotic theory; (ii) bootstrap, an automated inference procedure; (iii) generating non-standard distributions; (iv) approximating integrals with no analytic expressions. In this lecture, we will focus on (i) and (ii), whereas (iii) and (iv) will be deferred to the next lecture on integration.\n",
    "From now on, we will start to write script. A script is a piece of code for a particular purpose. We do not write a script of thousands of lines from the beginning to the end; we develop it recursively. We cut a big job into small manageable tasks. Write a small piece, test it, and perhaps encapsulate it into a user-defined function. Small pieces are integrated by the super structure. This is just like building an Airbus 380. The engines and wings are made in UK, the fuselage is made in Germany and so on. All pieces are assembled in Toulouse, France, and then the giant steel bird can fly. Finally, add comments to the script to facilitate readability. Without comments you will forget what you did when you open the script again one month later.\n",
    "\n",
    "**Example**\n",
    "\n",
    "Zu Chongzhi (429--500 AD), an ancient Chinese mathematician, calculated $\\pi$ being between 3.1415926 and 3.1415927, which for 900 years held the world record of the most accurate $\\pi$. He used a deterministic approximation algorithm. Now imagine that we present to Zu Chongzhi, with full respect and admiration, a modern PC. How can he achieve a better approximation? Of course, we suppose that he would not google it.\n",
    "\n",
    "Standing on the shoulder of laws of large numbers, $\\pi$ can be approximated by stochastic algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1344\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 10000\n",
    "Z = np.random.uniform(low = 0.0, high = 1.0, size = (n // 2, 2)) # uniform distribution ranging (0,1)\n",
    "X = Z - np.full((n // 2, 2), 0.5)\n",
    "Y = (X * X).sum(axis = 1)\n",
    "W = Y ** (1 / 2.0)\n",
    "inside = len([i for i in W if i <= 0.5]) / len(W) # the center of the cirle is (0.5,0.5)\n",
    "pi_hat = 4 * inside # the area of a circle = pi * r^2\n",
    "print(pi_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Sample Evaluation\n",
    "In the real world, a sample is finite. The distribution of a statistic in finite sample depends on the sample size $n$, which has simple a mathematical expression only in rare cases. Fortunately, the expression can often be simplified when we imagine the sample size being arbitrarily large. Asymptotic theory is such apparatus to approximate finite sample distributions. It is so far the best mathematical tool that helps us understand the behavior of estimators and tests, either in econometrics or in statistics in general. Simulation is one way to evaluate the accuracy of approximation.\n",
    "\n",
    "Even though real data empirical example can also be used to illustrate a statistical procedure, artificial data are convenient and boast advantages. The prevalent paradigm in statistics is to assume that the data are generated from a model. We, as researchers, check how close the estimate is to the model, which is often characterized by a set of unknown parameters. In simulation we have full control of the data generation process, so we also know the true parameter. In a real example, however, we have no knowledge about the true model, so we cannot directly evaluate the quality of parameter estimation.\n",
    "\n",
    "(It would be a different story if we are mostly interested in prediction, as we often encounter in machine learning. In such cases, we can split the data into two parts: one part for modeling and estimation, and the other for verification.)\n",
    "\n",
    "**Example**\n",
    "\n",
    "In OLS theory, the classical approach is to view $X$ as fixed regressions, and only cares about the randomness of the error term. Modern econometrics textbook emphasizes that a random $X$ is more appropriate for econometrics applications. In rigorous textbooks, the moment of $X$ is explicitly stated. Is asymptotic inferential theory for the OLS estimator---consistency and asymptotic normality---valid when $X$ follows a __[Pareto distribution](https://en.wikipedia.org/wiki/Pareto_distribution)__ with shape coefficient 1.5? (A Pareto distribution with shape coefficient between 1 and 2 has finite mean but infinite variance.)\n",
    "\n",
    "1. given sample size, get OLS b_hat and its associated t_value.\n",
    "2. wrap t_value as a user-defined function so that we can replicate for many times.\n",
    "3. given sample size, report the size under two distributions.\n",
    "4. wrap it again as a user-defined function, ready for different sample sizes.\n",
    "5. develop the super structure.\n",
    "6. add comments and documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact': [0.045, 0.06, 0.04, 0.043], 'normal.asym': [0.155, 0.08, 0.049, 0.044], 'cauchy.asym': [0.158, 0.098, 0.056, 0.023]}\n",
      "0:00:40.657456\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import datetime\n",
    "\n",
    "\n",
    "np.random.seed(888)\n",
    "#set the parameters\n",
    "Rep = 1000\n",
    "b0 = np.mat([[1], [1]])\n",
    "df = 1 #t dist. with df = 1 is Cauchy\n",
    "\n",
    "#the workhorse functions\n",
    "def simulation(n, type = 'Normal', df = df):\n",
    "    #a function gives the t-value under the null\n",
    "    if type == 'Normal':\n",
    "        e = np.random.normal(size = (n, 1))\n",
    "    elif type == 'T':\n",
    "        e = np.random.standard_t(df, size = (n, 1))\n",
    "\n",
    "    X = np.column_stack((np.full((n, 1), 1), np.random.pareto(1.5, size = (n, 1))))\n",
    "    Y = np.dot(X, b0) + e\n",
    "\n",
    "    del e\n",
    "\n",
    "    bhat = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, Y))\n",
    "    bhat2 = bhat[1]  #parameter we want to test\n",
    "\n",
    "    e_hat = Y - np.dot(X, bhat)\n",
    "    sigma_hat_square = np.dot(e_hat.T, e_hat) / (n - 2)\n",
    "    sig_B = np.linalg.inv(np.dot(X.T, X)) * np.array(sigma_hat_square)\n",
    "    t_value_2 = (bhat2 - b0[1, 0]) / (sig_B[1, 1] ** (1 / 2.0))\n",
    "\n",
    "    out = {'bhat2': bhat2, 't_value': t_value_2}\n",
    "    return out\n",
    "\n",
    "#report the empirical test size\n",
    "def report(n):\n",
    "    # collect the test size from the two distributions\n",
    "    # this function contains some repetitive code, but is OK for such a simple one\n",
    "    TEST_SIZE = [0, 0, 0]\n",
    "\n",
    "    # e ~ normal distribution, under which the t-dist is exact\n",
    "    normalRes = {'bhat2':([0] * Rep), 't_value':([0] * Rep)}\n",
    "\n",
    "    # e ~ t-distribution, under which the exact distribution is complicated.\n",
    "    # we rely on asymptotic normal distribution for inference instead\n",
    "    cauchyRes = {'bhat2':([0] * Rep), 't_value':([0] * Rep)}\n",
    "    for i in range(Rep):\n",
    "        normalRes['bhat2'][i] = simulation(n, 'Normal')['bhat2']\n",
    "        normalRes['t_value'][i] = simulation(n, 'Normal')['t_value']\n",
    "        cauchyRes['bhat2'][i] = simulation(n, 'T', df)['bhat2']\n",
    "        cauchyRes['t_value'][i] = simulation(n, 'T', df)['t_value']\n",
    "\n",
    "\n",
    "    TEST_SIZE[0] = len([normalRes['t_value'][i][0][0] for normalRes['t_value'][i] in normalRes['t_value'] if abs(normalRes['t_value'][i][0][0]) > stats.t.ppf(q=0.975, df=n - 2)]) / float(len(normalRes['t_value']))\n",
    "    TEST_SIZE[1] = len([normalRes['t_value'][i][0][0] for normalRes['t_value'][i] in normalRes['t_value'] if abs(normalRes['t_value'][i][0][0]) > stats.norm.ppf(q=0.975)]) / float(len(normalRes['t_value']))\n",
    "    TEST_SIZE[2] = len([cauchyRes['t_value'][i][0][0] for cauchyRes['t_value'][i] in cauchyRes['t_value'] if abs(cauchyRes['t_value'][i][0][0]) > stats.norm.ppf(q=0.975)]) / float(len(cauchyRes['t_value']))\n",
    "\n",
    "    return TEST_SIZE\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pts0 = datetime.datetime.now()\n",
    "    # run the calculation of the empirical sizes for different sample sizes\n",
    "    NN = np.array([5, 10, 200, 5000])\n",
    "    RES = {'exact':([0] * (len(NN))), 'normal.asym':([0] * (len(NN))), 'cauchy.asym':([0] * (len(NN)))}\n",
    "    for i in range(len(NN)):\n",
    "        RES['exact'][i] = report(NN[i])[0]\n",
    "        RES['normal.asym'][i] = report(NN[i])[1]\n",
    "        RES['cauchy.asym'][i] = report(NN[i])[2]\n",
    "    print(RES)\n",
    "    print(datetime.datetime.now() - pts0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the table, we witness that the distribution of $X$ indeed does not matter. Why? $$ \\sqrt{n} (\\hat{\\beta} - \\beta_0) = (X'X/n)^{-1} (X'e/\\sqrt{n}) $$ Even though $X'X/n$ does not converge, the self-normalized $t$ statistic is immune of the problem. What matters is the distribution of the error term. The first column is the when the error is normal, and we use the exactly distribution theory to find the critical value (according to the $t$ distribution.) The second column still uses the normal distribution in the error term, but change the critical value to be from the normal distribution, which is based on asymptotic approximation. When sample size is small, obvious size distortion is observed; but the deviation is mitigated when the sample size increases. When the error distribution is Cauchy, the so called \"exact distribution\" is not longer exact--- it is exact only if the error is normal and independent from $x$. If we attempt to use the asymptotic normal approximation, we find that the asymptotic approximation breaks down. The test size does not converge to the nominal 5% as the sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap\n",
    "Bootstrap, originated from Efron (1979), is an extremely powerful and influential idea for estimation and inference.\n",
    "\n",
    "Let $X_1, X_2, \\ldots, X_n \\sim F$ be an i.i.d. sample of $n$ observations following a distribution $F$. The finite sample distribution of a statistic $T_n(\\theta)\\sim G_n(\\cdot, F)$ usually depends on the sample size $n$, as well as the known true distribution $F$. Asymptotic theory approximates $G_n(\\cdot, F)$ by its limit $$G(\\cdot, F) := \\lim_{n\\to\\infty} G_n(\\cdot, F);$$ if $T_n(\\theta)$ is asymptotically pivotal, then $G_n(\\cdot, F)$ is independent of $F$.\n",
    "\n",
    "Instead of referring to the limiting distribution, Bootstrap replaces the unknown distribution $F$ in $G_n(\\cdot, F)$ by a consistent estimator $F_n$ of the true distribution, for example, the empirical distribution function. Bootstrap inference is drawn from the bootstrap distribution $$ G^{*}_n(\\cdot):= G_n(\\cdot, F_n) $$\n",
    "\n",
    "Implementation of bootstrap is almost always a Monte Carlo simulation. In i.i.d. environment we sample over each observation with equal weight, while in dependent dataset such as time series, clustering data or networks, we must adjust the sampling schedule to preserve the dependence structure.\n",
    "\n",
    "In many regular cases, it is possible to show in theory the consistency of bootstrap: the statistic of interest and its bootstrap version converge to the same asymptotic distribution, or $G^*_n(a)\\to G(a)$ for $a$ such that $G(a)$ is continuous. However, bootstrap consistency can fail when the distribution of the statistic is discontinuous in the limit. Bootstrap is invalid in such cases. For instance, naive bootstrap fails to replicate the asymptotic distribution of the two-stage least squares estimator under weak instruments.\n",
    "\n",
    "### Bootstrap Estimation\n",
    "Bootstrap is simple enough to be done by a ply-family function for repeated simulations. Alternatively, R package boot provides a general function boot().\n",
    "\n",
    "Bootstrap is useful when the analytic formula of the variance of an econometric estimator is too complex to derive or code up.\n",
    "\n",
    "#### Example\n",
    "One of the most popular estimators for a sample selection model is Heckman(1979)'s two-step method. Let the outcome equation be $$y_i = x_i \\beta + u_i$$ and the selection equation be $$D_i = z_i \\gamma + v_i$$ To obtain a point estimator, we simply run a Probit in the selection model, predict the probability of participation, and then run an OLS of $y_i$ on $x_i$ and $\\lambda (\\hat{D}_i)$ in the outcome model, where $\\lambda(\\cdot)$ is the inverse Mill's ratio. However, as we can see from Heckman(1979)'s original paper, the asymptotic variance expression of the two-step estimator is very complicated. Instead of following the analytic formula, we bootstrap the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\n",
      "z test of coefficients:\n",
      "\r\n",
      "\n",
      "\r\n",
      "                 Estimate  Std. Error z value  Pr(>|z|)    \n",
      "\r\n",
      "(Intercept)   -1.1385e-01  4.0442e-01 -0.2815  0.778319    \n",
      "\r\n",
      "age           -3.6696e-02  6.7110e-03 -5.4680 4.552e-08 ***\n",
      "\r\n",
      "faminc         1.0319e-05  4.3393e-06  2.3780  0.017409 *  \n",
      "\r\n",
      "exper          7.4511e-02  7.2030e-03 10.3444 < 2.2e-16 ***\n",
      "\r\n",
      "educ           6.8872e-02  2.3978e-02  2.8723  0.004075 ** \n",
      "\r\n",
      "(Intercept)   -1.9500e+00  1.8023e+00 -1.0819  0.279277    \n",
      "\r\n",
      "exper          1.6062e-02  3.3892e-02  0.4739  0.635554    \n",
      "\r\n",
      "educ           4.8147e-01  8.2271e-02  5.8523 4.848e-09 ***\n",
      "\r\n",
      "invMillsRatio -3.0324e-01  9.8862e-01 -0.3067  0.759051    \n",
      "\r\n",
      "sigma          3.1080e+00          NA      NA        NA    \n",
      "\r\n",
      "rho           -9.7565e-02          NA      NA        NA    \n",
      "\r\n",
      "---\n",
      "\r\n",
      "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\r\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import rpy2\n",
    "from rpy2.robjects import r\n",
    "r('''install.packages('sampleSelection')''')\n",
    "r('''install.packages('lmtest')''')\n",
    "r('''library(sampleSelection)''')\n",
    "r('''library(lmtest)''')\n",
    "r('''data(Mroz87)''')\n",
    "r('''selection_eq = lfp ~age + faminc + exper + educ''')\n",
    "r('''outcome_eq = wage ~ exper + educ''')\n",
    "r('''heck = heckit(selection_eq, outcome_eq, data = Mroz87)''')\n",
    "heckCoefTest = r('''coeftest(heck)''')\n",
    "print(heckCoefTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function for a single bootstrap. For convenience, I keep using heckit but only save the point estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "from rpy2.robjects import r\n",
    "def boot_heck():\n",
    "    r('''library(sampleSelection)''')\n",
    "    r('''library(lmtest)''')\n",
    "    r('''data(Mroz87)''')\n",
    "    r('''selection_eq = lfp ~age + faminc + exper + educ''')\n",
    "    r('''outcome_eq = wage ~ exper + educ''')\n",
    "    r('''n = nrow(Mroz87);\n",
    "    indices = sample(1:n, n, replace = T);\n",
    "    Mroz87_b = Mroz87[indices,]\n",
    "    ''')\n",
    "    heck_b = r('''coef(heckit(selection_eq, outcome_eq, data = Mroz87_b))''')\n",
    "    return (heck_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation is just a repeated evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    selection_intercept         age       faminc selection_exper  \\\n",
      "sd             0.410106  0.00702412  4.73325e-06      0.00784671   \n",
      "\n",
      "   selection_educ outcome_intercept outcome_exper outcome_educ invMillsRatio  \\\n",
      "sd      0.0248566            2.4349     0.0422959    0.0986313       1.55759   \n",
      "\n",
      "      sigma       rho  \n",
      "sd  0.40795  0.448673  \n"
     ]
    }
   ],
   "source": [
    "boot_Rep = 199\n",
    "column_names = ['selection_intercept', 'age', 'faminc', 'selection_exper', 'selection_educ', 'outcome_intercept', 'outcome_exper', 'outcome_educ', 'invMillsRatio', 'sigma', 'rho']\n",
    "Heck_B = pd.DataFrame(index = range(boot_Rep), columns = column_names)\n",
    "for i in range(boot_Rep):\n",
    "    Heck_B.iloc[i,:] = boot_heck()\n",
    "Heck_b_sd = pd.DataFrame(index = ['sd'], columns = column_names)\n",
    "for i in range(len(column_names)):\n",
    "    Heck_b_sd.iloc[:, i] = statistics.stdev(Heck_B.iloc[:,i])\n",
    "print(Heck_b_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Test\n",
    "Bootstrap is particularly helpful in inference. Indeed, we can rigorously prove that bootstrap enjoys high-order improvement relative to asymptotic approximation if the test statistic is asymptotically pivotal. Loosely speaking, if the test statistic is asymptotically pivotal, a bootstrap hypothesis testing can be more accurate than its analytic asymptotic counterpart.\n",
    "#### Example\n",
    "We use bootstrap to test a hypothesis about the population mean. The test is carried out via by a $t$-statistic. The distribution of the sample is either normal or zero-centered chi-square. It will show that the bootstrap test size is more precise than that of the asymptotic approximation.\n",
    "\n",
    "We first prepare the workhorse functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "#the t-statistic for a null hypothesis mu\n",
    "def T_stat(Y, mu, n):\n",
    "    t_stat = (n ** (1 / 2.0)) * (statistics.mean(Y) - mu) / statistics.stdev(Y)\n",
    "    return t_stat\n",
    "\n",
    "#the bootstrap function\n",
    "def boot_test(Y, boot_Rep, alpha, n, mu):\n",
    "    #INPUT Y: the sample boot_Rep: number of bootstrap replications\n",
    "    lenY = len(Y)\n",
    "    boot_T = [0] * boot_Rep\n",
    "\n",
    "    #bootstrap in action\n",
    "    for r in range(boot_Rep):\n",
    "        indices = np.random.choice(range(lenY), size = lenY, replace = True) #resampling the index\n",
    "        resampled_Y = [Y[i] for i in indices] #construct a bootstrap artificial sample\n",
    "        boot_T[r] = abs(T_stat(resampled_Y, statistics.mean(Y), n))\n",
    "        #the bootstrapped t-statistic mu is replaced by 'mean(Y)' to mimic the situation under the null\n",
    "\n",
    "    #bootstrap critical value\n",
    "    boot_critical_value = (pd.DataFrame(boot_T)).quantile(1 - alpha)[0]\n",
    "\n",
    "    #bootstrap test decision\n",
    "    return int(abs(T_stat(Y, mu, n)) > boot_critical_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key point for bootstrap test is that the null hypothesis must be imposed no matter the hypothesized parameter is true value or not. Therefore the bootstrap t-statistic is $$ T^{}_{n} = \\frac{\\bar{X^{}} - \\bar{X}} { s^{*} / \\sqrt{n} }. $$ That is, the bootstrap $t$-statistic is centered at $\\bar{X}$, the sample mean of $F_n$, rather than $\\theta$, the population mean of $F$. This is because in the bootstrap world the ``true'' distribution is $F_n$. If we wrongly center the bootstrap t-statistic at $\\theta$, then the test will have no power when the null hypothesis is false.\n",
    "\n",
    "The following chuck of code report the rejection probability from three decision rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(distribution, boot_Rep, alpha, n, mu):\n",
    "    #this function generates a sample of n observations and it returns the testing results from three decision rules\n",
    "    if distribution == 'normal':\n",
    "        X = np.random.normal(size =(n,))\n",
    "    elif distribution == 'chisq':\n",
    "        X = np.random.chisquare(df = 3, size = n) - 3\n",
    "\n",
    "    t_value_X = T_stat(X, mu, n) #T-statistic\n",
    "\n",
    "    #compare it to the 97.5% of t-distribution\n",
    "    exact = int(abs(t_value_X) > stats.t.ppf(q = 0.975, df = n - 1))\n",
    "\n",
    "    #compare it to the 97.5% of normal distribution\n",
    "    asym = int(abs(t_value_X) > 1.96)\n",
    "\n",
    "    #decision from bootstrap\n",
    "    boot_decision = boot_test(X, boot_Rep, alpha, n, mu)\n",
    "\n",
    "    return [exact, asym, boot_decision]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the nominal size of the test is 5%. The program reports the empirical size ---the ratio between the number of rejections to the total number of replications. The closer is the empirical size to the nominal size, the more accurate is the test. We find here the bootstrap test is better than the asymptotic test.\n",
    "\n",
    "When the underlying distribution is a $\\chi^2$, there is no explicit exact distribution. However, we can still compare the asymptotic size with the bootstrap size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact        0.0440\n",
      "asym         0.0620\n",
      "bootstrap    0.0465\n",
      "Name: 2000, dtype: float64\n",
      "exact        0.0740\n",
      "asym         0.0900\n",
      "bootstrap    0.0655\n",
      "Name: 2000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    n = 20\n",
    "    distribution = 'normal'\n",
    "    boot_Rep = 199\n",
    "    MC_rep = 2000\n",
    "    alpha = 0.05\n",
    "    mu = 0\n",
    "\n",
    "    np.random.seed(111)\n",
    "\n",
    "    #Monte Carlo simulation and report the rejection probability\n",
    "    column_name = ['exact', 'asym', 'bootstrap']\n",
    "    norm_res = pd.DataFrame(index = range(MC_rep + 1), columns = column_name)\n",
    "    for i in range(MC_rep + 1):\n",
    "        norm_res.iloc[i, :] = compare(distribution, boot_Rep, alpha, n, mu)\n",
    "        if i == MC_rep:\n",
    "            for j in range(3):\n",
    "                norm_res.iloc[MC_rep, j] = (norm_res.iloc[:MC_rep, j]).mean()\n",
    "    print(norm_res.iloc[MC_rep, :])\n",
    "\n",
    "    distribution = 'chisq'\n",
    "    np.random.seed(666)\n",
    "\n",
    "    #Simulate and report the rejection probability\n",
    "    chisq_res = pd.DataFrame(index = range(MC_rep + 1), columns = column_name)\n",
    "    for i in range(MC_rep + 1):\n",
    "        chisq_res.iloc[i, :] = compare(distribution, boot_Rep, alpha, n, mu)\n",
    "        if i == MC_rep:\n",
    "            for j in range(3):\n",
    "                chisq_res.iloc[MC_rep, j] = (chisq_res.iloc[:MC_rep, j]).mean()\n",
    "    print(chisq_res.iloc[MC_rep, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, here the \"exact test\" is no longer exact. The asymptotic test works fairly reasonable, while the bootstrap is closer to the nominal size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
